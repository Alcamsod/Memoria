# Predicci√≥n del Precio de la Luz con XGBoost

## üìî Descripci√≥n del Proyecto

Este cuaderno de Jupyter implementa un modelo ***XGBoost*** (eXtreme Gradient Boosting). Este es un algoritmo de machine learning basado en √°rboles de decisi√≥n optimizado para velocidad y rendimiento. Este modelo tiene como caracter√≠sticas principales:

- **Modelado No Lineal:** Permite modelar interacciones complejas y patrones no lineales en los datos.

- **Importancia de Variables:** Proporciona m√©tricas para evaluar la relevancia de cada predictor.

- **Regularizaci√≥n:** Incorpora t√©cnicas para evitar el sobreajuste y mejorar la generalizaci√≥n.

El proceso consiste en:

- **Obtenci√≥n de Variables Temporales:** Como XGBoost no modela expl√≠citamente la temporalidad, es fundamental construir caracter√≠sticas que representen la din√°mica de la serie, tales como rezagos (lags), medias m√≥viles o variables estacionales (d√≠a de la semana, hora del d√≠a).

- **B√∫squeda de Hiperpar√°metros (GridSearch):** Se implementa una b√∫squeda sistem√°tica (GridSearchCV) para encontrar la mejor combinaci√≥n de par√°metros como n√∫mero de √°rboles, profundidad m√°xima, tasa de aprendizaje, y regularizaci√≥n.

- **Validaci√≥n Cruzada Temporal (TimeSeriesSplit)**: Se usa TimeSeriesSplit para respetar el orden cronol√≥gico de los datos, asegurando que el modelo se valide con datos posteriores a los que us√≥ para entrenar.

- **Ajuste del Modelo:** Con los hiperpar√°metros √≥ptimos, se entrena el modelo final sobre el conjunto de entrenamiento.

La predicci√≥n con XGBoost se realiza de forma recursiva:

- **Reentrenamiento:** Se reentrena el modelo final con todos los datos hist√≥ricos disponibles para aprovechar toda la informaci√≥n.

- **Predicci√≥n Paso a Paso:** Para predecir el horizonte futuro el modelo:

    - Predice el primer paso (t+1) usando los datos hist√≥ricos reales y las variables derivadas.

    - Para predecir el segundo paso (t+2), utiliza los datos hist√≥ricos y la predicci√≥n previa para t+1 como si fuera un dato real, actualizando las variables temporales en cada paso.

Este m√©todo permite a XGBoost adaptarse a la predicci√≥n de series temporales, siempre que las caracter√≠sticas temporales est√©n bien dise√±adas.

## üéØ Objetivo

- Predecir el precio horario de la electricidad para un conjunto de tiempo deseado, en este caso a un mes vista.

## üìÅ Estructura del Script

1. **Carga de datos** ``CSV`` desde rutas locales.
2. **Preprocesamiento**:
   - Conversi√≥n temporal
   - Alineaci√≥n por hora
   - Eliminaci√≥n de valores nulos
3. **Creaci√≥n de caracter√≠sticas**:
   - Lags (t-1, t-24, t-168)
   - Estad√≠sticas m√≥viles (media y desviaci√≥n)
   - Variables temporales (hora, d√≠a de la semana, mes)
4. **Divisi√≥n del dataset**:
   - Entrenamiento, validaci√≥n y predicci√≥n final
5. **An√°lisis Exploratorio**:
   - Gr√°ficos temporales
   - Boxplots por hora y mes
   - Matriz de correlaci√≥n
6. **Entrenamiento del modelo**:
   - Ajuste directo o mediante ``GridSearchCV``
7. **Evaluaci√≥n del rendimiento**:
   - ``MAE`` y ``RMSE``
   - Importancia de variables
   - Visualizaci√≥n comparativa real vs. predicci√≥n
8. **Predicci√≥n final y visualizaci√≥n** para un periodo objetivo
9. **An√°lisis de errores**:
   - Distribuci√≥n
   - Q-Q plots
   - Boxplots
   - Normalidad de residuos

---

## üìä Variables Consideradas

- `precio`: variable objetivo
- `generacion_eolica`: variable ex√≥gena (lag 24h)
- `generacion_solar`: variable ex√≥gena (lag 24h)
- `demanda_real`: variable ex√≥gena (lag 24h)
- `lag_1`, `lag_24`, `lag_168`: precios pasados
- `rolling_mean_24`, `rolling_std_24`: media y desviaci√≥n m√≥viles
- `hora`, `dia_semana`, `mes`: variables temporales


## üì¶ Requisitos

Los paquetes utilizados se incluyen en el requirements (py 3.10):

``pip install -r requirements.txt``

## ‚úÖ Resultados

### Modelo 2.1

   - df['lag_1'] = df['precio'].shift(1)
   - df['lag_24'] = df['precio'].shift(24)
   - df['lag_168'] = df['precio'].shift(168)
   - df['rolling_mean_24'] = df['precio'].rolling(24).mean()
   - df['rolling_std_24'] = df['precio'].rolling(24).std()

**Train-Test set:** 70/30

---

**Hiperpar√°metros √≥ptimos encontrados:**
- learning_rate': 0.04
- 'max_depth': 3
- 'n_estimators': 375
- Mejor MAE con validaci√≥n cruzada: 6.00
---
Evaluaci√≥n sobre el modelo:

| M√©trica | Test | Predicci√≥n | 
|---|---|---|
| **MAE** | 7.2982 | 7.4319 |
| **RMSE** | 11.0834 | 12.2298 |
| **R¬≤** | 0.9548 | 0.9434 |
---
### Modelo 2.2

- df['lag_1'] = df['precio'].shift(1)
- df['lag_24'] = df['precio'].shift(24)
- df['lag_168'] = df['precio'].shift(168)
- df['rolling_mean_24'] = df['precio'].rolling(24).mean()
- df['rolling_std_24'] = df['precio'].rolling(24).std()


**Train-Test set:** 90/10

---

**Hiperpar√°metros √≥ptimos encontrados:**
- learning_rate': 0.04
- 'max_depth': 3
- 'n_estimators': 375
- Mejor MAE con validaci√≥n cruzada: 6.00
---
Evaluaci√≥n sobre el modelo:

| M√©trica | Test | Predicci√≥n | 
|---|---|---|
| **MAE** | 6.3381 | 6.7529 |
| **RMSE** | 10.7758 | 11.1385 |
| **R¬≤** | 0.9164 | 0.9530 |
---
### Modelo 2.3

   - df['lag_1'] = df['precio'].shift(1)
   - df['lag_24'] = df['precio'].shift(24)
   - df['lag_168'] = df['precio'].shift(168)
   - df['rolling_mean_24'] = df['precio'].rolling(24).mean()
   - df['rolling_std_24'] = df['precio'].rolling(24).std()
   - df['rolling_mean_24_eolica'] = df['generacion_eolica'].rolling(24).mean()
   - df['rolling_std_24_eolica'] = df['generacion_eolica'].rolling(24).std()
   - df['rolling_mean_24_solar'] = df['generacion_solar'].rolling(24).mean()
   - df['rolling_std_24_solar'] = df['generacion_solar'].rolling(24).std()
   - df['rolling_mean_24_demanda'] = df['demanda_real'].rolling(24).mean()
   - df['rolling_std_24_demanda'] = df['demanda_real'].rolling(24).std()

**Train-Test set:** 90/10

---

**Hiperpar√°metros √≥ptimos encontrados:**
- learning_rate': 0.03
- 'max_depth': 3
- 'n_estimators': 300
- Mejor MAE con validaci√≥n cruzada: 6.11


---
Evaluaci√≥n sobre el modelo:

| M√©trica | Test | Predicci√≥n | 
|---|---|---|
| **MAE** | 7.6670 | 7.7443 |
| **RMSE** | 11.5923 | 12.9418 |
| **R¬≤** | 0.9505 | 0.9366 |
---
### Modelo 2.3

   - df['lag_1'] = df['precio'].shift(1)
   - df['lag_24'] = df['precio'].shift(24)
   - df['lag_168'] = df['precio'].shift(168)
   - df['rolling_mean_24'] = df['precio'].rolling(24).mean()
   - df['rolling_std_24'] = df['precio'].rolling(24).std()
   - df['rolling_mean_24_eolica'] = df['generacion_eolica'].rolling(24).mean()
   - df['rolling_std_24_eolica'] = df['generacion_eolica'].rolling(24).std()
   - df['rolling_mean_24_solar'] = df['generacion_solar'].rolling(24).mean()
   - df['rolling_std_24_solar'] = df['generacion_solar'].rolling(24).std()
   - df['rolling_mean_24_demanda'] = df['demanda_real'].rolling(24).mean()
   - df['rolling_std_24_demanda'] = df['demanda_real'].rolling(24).std()

**Train-Test set:** 90/10

---
**Hiperpar√°metros √≥ptimos encontrados:**
- learning_rate': 0.03
- 'max_depth': 3
- 'n_estimators': 300
- Mejor MAE con validaci√≥n cruzada: 6.11

---

Evaluaci√≥n sobre el modelo:

| M√©trica | Test | Predicci√≥n | 
|---|---|---|
| **MAE** | 6.2932 | 7.4174 |
| **RMSE** | 9.4810 | 12.0819 |
| **R¬≤** | 0.8947 | 0.9447 |
---